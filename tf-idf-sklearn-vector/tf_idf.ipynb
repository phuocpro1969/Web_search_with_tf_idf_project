{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import time\n",
    "from nltk import stem \n",
    "from nltk.corpus import stopwords \n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILES = \"./input/Cranfield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear text\n",
    "def remove_special_character(text):\n",
    "    processed_text = text.lower()\n",
    "    processed_text = processed_text.replace(\"’\", \"'\")\n",
    "    processed_text = processed_text.replace(\"“\", '\"')\n",
    "    processed_text = processed_text.replace(\"”\", '\"')\n",
    "\n",
    "    non_words = re.compile(r\"[^A-Za-z']+\")\n",
    "    processed_text = re.sub(non_words, ' ', processed_text)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "def remove_stopwords(text): # step 1\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # xóa stopwords\n",
    "    words = [\n",
    "        w for w in text.split(\" \")\n",
    "        if w not in stop_words\n",
    "    ]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_punctuation(text): # step 2\n",
    "    words=[\n",
    "        char for char in text.split(\" \") \n",
    "        if char not in string.punctuation\n",
    "    ]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def remove_stem(text): # step 3\n",
    "    porter = PorterStemmer()\n",
    "    token_words = word_tokenize(text)\n",
    "    words = [\n",
    "        porter.stem(word) for word in token_words\n",
    "    ]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    # processing\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_special_character(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stem(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Read data \n",
    "def get_text_from_file(filename):\n",
    "    with open(filename, encoding='cp1252', mode='r') as f:\n",
    "        text = f.read()\n",
    "    f.close()\n",
    "    return text\n",
    "\n",
    "def read_data():\n",
    "    data = []\n",
    "    arr_file = []\n",
    "    for doc_file in os.listdir(INPUT_FILES):\n",
    "        filename = os.path.join(INPUT_FILES, doc_file)\n",
    "        text = get_text_from_file(filename)\n",
    "        if len(text) == 0:\n",
    "            continue\n",
    "        arr_file.append(doc_file.split(\".\")[0])\n",
    "        data.append(clear_text(text))\n",
    "    return data, arr_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index, tf_idf arrays\n",
    "def build_tf_idf_sklearn(data):\n",
    "    tfidfVectorizer = TfidfVectorizer(\n",
    "        analyzer='word', ngram_range=(1,6), min_df=0.01, sublinear_tf=True, \n",
    "        use_idf=True, smooth_idf=True\n",
    "    )\n",
    "\n",
    "    tfidf_matrix =  tfidfVectorizer.fit_transform(data)\n",
    "    feature_names = tfidfVectorizer.get_feature_names()\n",
    "    \n",
    "    # init\n",
    "    tfidf_scores = dict()\n",
    "    for index in feature_names:\n",
    "        tfidf_scores[index] = []\n",
    "    for index in range(len(data)):\n",
    "        feature_index = tfidf_matrix[index,:].nonzero()[1]\n",
    "        for x in feature_index:\n",
    "            tfidf_scores[feature_names[x]].append([index, tfidf_matrix[index, x]])\n",
    "    return tfidfVectorizer, tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_queries():\n",
    "    result = dict()\n",
    "    for i in open(\"./input/query.txt\").readlines():\n",
    "        t = i.split('\\t')\n",
    "        result[t[0]] = t[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ground_truth():\n",
    "    path = os.path.join('./input', 'RES')\n",
    "    data = dict()\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.path.join(path, file)\n",
    "        text = get_text_from_file(filename)\n",
    "        text = text.rstrip('\\n')\n",
    "        cutLine = text.split('\\n')\n",
    "        for index, line in enumerate(cutLine):\n",
    "            # cutTab[1] chua can quan tam toi do chua can dung\n",
    "            cutTab = line.split('\\t')\n",
    "            cutSpace = cutTab[0].split(\" \")\n",
    "            if cutSpace[0] not in data.keys():\n",
    "                data[cutSpace[0]] = [cutSpace[1]]\n",
    "            else:\n",
    "                data[cutSpace[0]].append(cutSpace[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_ranking_for_query( query, tfidfVectorizer, tfidf_scores, feature_names, arr_file):\n",
    "    # clear query \n",
    "    query = clear_text(query)\n",
    "    query = \" \".join(\n",
    "        [ \n",
    "            word for word in query.split(\" \") \n",
    "            if word in feature_names\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # compute tf_idf\n",
    "    tfidf_matrix =  tfidfVectorizer.fit_transform([query])\n",
    "    feature_index = tfidf_matrix[0,:].nonzero()[1]\n",
    "    \n",
    "    # get vocal in query\n",
    "    feature_names_query = tfidfVectorizer.get_feature_names()\n",
    "    \n",
    "    # check word in vocal\n",
    "    query_tfidf_scores = dict()\n",
    "\n",
    "    for x in feature_index:\n",
    "        if feature_names_query[x] in feature_names:\n",
    "            if feature_names_query[x] not in query_tfidf_scores.keys():\n",
    "                query_tfidf_scores[feature_names_query[x]] = [tfidf_matrix[0, x]]\n",
    "            else:\n",
    "                query_tfidf_scores[feature_names_query[x]].append(tfidf_matrix[0, x])\n",
    "\n",
    "    # find q length\n",
    "    q_length = 0\n",
    "\n",
    "    relevant_between_words = dict()\n",
    "    # compute relevant query and data_train\n",
    "    relevant_between_words = {\n",
    "        word: [\n",
    "            [\n",
    "                item[0],\n",
    "                item[1] * query_tfidf_scores[word][0]\n",
    "            ] for item in tfidf_scores[word]\n",
    "        ] for word in query_tfidf_scores.keys()\n",
    "    }\n",
    "\n",
    "    for key, value in query_tfidf_scores.items():\n",
    "        q_length += math.pow(value[0], 2)\n",
    "    q_length = math.sqrt(q_length)\n",
    "\n",
    "    q_score = dict()\n",
    "    for _, value in relevant_between_words.items():\n",
    "        for i in value:\n",
    "            if i[0] not in q_score.keys():\n",
    "                q_score[i[0]] = i[1]\n",
    "            else:\n",
    "                q_score[i[0]] += i[1]\n",
    "    for key in q_score.keys():\n",
    "        q_score[key] = q_score[key] / (q_length + 0.01)\n",
    "    \n",
    "    # rank\n",
    "    q = sorted(q_score.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    x_retrieved = []\n",
    "    for i in q:\n",
    "        x_retrieved.append(arr_file[i[0]])\n",
    "    return x_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Average_Precision(x_retrieved, relevant_docs):\n",
    "    # find R_Precision value\n",
    "    validation_result = {'R': [], 'P': []}\n",
    "    c = 0\n",
    "    for i in range(len(x_retrieved)):\n",
    "        if x_retrieved[i] in relevant_docs:\n",
    "            c += 1\n",
    "        validation_result['R'].append((c / len(relevant_docs)))\n",
    "        validation_result['P'].append((c / (i + 1)))\n",
    "    return sum(validation_result['P']) / len(validation_result['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        pkl_file = open(os.path.join('.\\input', 'data', 'train.pickle'), 'rb')\n",
    "        arr_file = pickle.load(pkl_file)\n",
    "        tfidfVectorizer = pickle.load(pkl_file)\n",
    "        tfidf_scores = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "    except:\n",
    "        data, arr_file = read_data()\n",
    "        tfidfVectorizer, tfidf_scores = build_tf_idf_sklearn(data)\n",
    "        with open(os.path.join('.\\input', 'data', 'train.pickle'), mode='wb') as f:\n",
    "            pickle.dump(arr_file, f)\n",
    "            pickle.dump(tfidfVectorizer, f)\n",
    "            pickle.dump(tfidf_scores, f)\n",
    "        f.close()\n",
    "        \n",
    "    feature_names = tfidfVectorizer.get_feature_names()\n",
    "    queries = open_queries()\n",
    "    list_of_x_retrieved = dict()\n",
    "    for key, query in queries.items():\n",
    "        list_of_x_retrieved[key] = get_relevant_ranking_for_query(\n",
    "            query, tfidfVectorizer, tfidf_scores, feature_names, arr_file\n",
    "        )\n",
    "    \n",
    "     # Bắt đầu đánh giá mô hình.\n",
    "    data_ground_truth = get_data_ground_truth()\n",
    "    Average_precision_of_all_x_retrieved = \\\n",
    "        {\n",
    "            key: get_Average_Precision(value, data_ground_truth[key])\n",
    "            for key, value in list_of_x_retrieved.items()\n",
    "        }\n",
    "    MAP = 0\n",
    "    for key, value in Average_precision_of_all_x_retrieved.items():\n",
    "        MAP += value\n",
    "    MAP = MAP / len(Average_precision_of_all_x_retrieved)\n",
    "    print(\"MAP:\", MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuoc\\.conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.03229645102700793\n",
      "Time elapsed:  0.8356642999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuoc\\.conda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "t0= time.clock()\n",
    "main()\n",
    "t1 = time.clock() - t0\n",
    "print(\"Time elapsed: \", t1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12',\n",
       " '746',\n",
       " '429',\n",
       " '141',\n",
       " '700',\n",
       " '51',\n",
       " '92',\n",
       " '1169',\n",
       " '884',\n",
       " '14',\n",
       " '1042',\n",
       " '606',\n",
       " '876',\n",
       " '1089',\n",
       " '724',\n",
       " '100',\n",
       " '878',\n",
       " '502',\n",
       " '1263',\n",
       " '316',\n",
       " '1379',\n",
       " '184',\n",
       " '658',\n",
       " '810',\n",
       " '1170',\n",
       " '834',\n",
       " '172',\n",
       " '875',\n",
       " '792',\n",
       " '195',\n",
       " '253',\n",
       " '982',\n",
       " '1147',\n",
       " '862',\n",
       " '578',\n",
       " '1111',\n",
       " '280',\n",
       " '747',\n",
       " '374',\n",
       " '416',\n",
       " '726',\n",
       " '1063',\n",
       " '1380',\n",
       " '909',\n",
       " '1361',\n",
       " '1158',\n",
       " '486',\n",
       " '293',\n",
       " '214',\n",
       " '284',\n",
       " '883',\n",
       " '896',\n",
       " '725',\n",
       " '378',\n",
       " '835',\n",
       " '321',\n",
       " '607',\n",
       " '78',\n",
       " '75',\n",
       " '430',\n",
       " '1303',\n",
       " '1299',\n",
       " '47',\n",
       " '672',\n",
       " '781',\n",
       " '729',\n",
       " '1163',\n",
       " '67',\n",
       " '263',\n",
       " '36',\n",
       " '203',\n",
       " '870',\n",
       " '481',\n",
       " '82',\n",
       " '840',\n",
       " '202',\n",
       " '364',\n",
       " '579',\n",
       " '804',\n",
       " '925',\n",
       " '712',\n",
       " '1217',\n",
       " '435',\n",
       " '1168',\n",
       " '497',\n",
       " '1051',\n",
       " '1088',\n",
       " '285',\n",
       " '588',\n",
       " '886',\n",
       " '805',\n",
       " '624',\n",
       " '640',\n",
       " '38',\n",
       " '860',\n",
       " '836',\n",
       " '209',\n",
       " '1255',\n",
       " '945',\n",
       " '1087',\n",
       " '453',\n",
       " '142',\n",
       " '288',\n",
       " '1331',\n",
       " '908',\n",
       " '1095',\n",
       " '251',\n",
       " '1246',\n",
       " '833',\n",
       " '244',\n",
       " '663',\n",
       " '2',\n",
       " '345',\n",
       " '1043',\n",
       " '574',\n",
       " '415',\n",
       " '798',\n",
       " '395',\n",
       " '1309',\n",
       " '1124',\n",
       " '264',\n",
       " '1283',\n",
       " '1002',\n",
       " '1279',\n",
       " '911',\n",
       " '204',\n",
       " '1320',\n",
       " '33',\n",
       " '220',\n",
       " '1015',\n",
       " '1012',\n",
       " '637',\n",
       " '629',\n",
       " '987',\n",
       " '837',\n",
       " '309',\n",
       " '731',\n",
       " '986',\n",
       " '29',\n",
       " '328',\n",
       " '69',\n",
       " '1144',\n",
       " '799',\n",
       " '493',\n",
       " '108',\n",
       " '24',\n",
       " '46',\n",
       " '1294',\n",
       " '436',\n",
       " '1167',\n",
       " '476',\n",
       " '650',\n",
       " '981',\n",
       " '187',\n",
       " '1295',\n",
       " '715',\n",
       " '1300',\n",
       " '1180',\n",
       " '997',\n",
       " '1197',\n",
       " '711',\n",
       " '1328',\n",
       " '390',\n",
       " '576',\n",
       " '1011',\n",
       " '1110',\n",
       " '52',\n",
       " '320',\n",
       " '589',\n",
       " '552',\n",
       " '593',\n",
       " '1202',\n",
       " '756',\n",
       " '721',\n",
       " '329',\n",
       " '1321',\n",
       " '1155',\n",
       " '641',\n",
       " '723',\n",
       " '914',\n",
       " '1148',\n",
       " '1265',\n",
       " '846',\n",
       " '581',\n",
       " '238',\n",
       " '811',\n",
       " '102',\n",
       " '466',\n",
       " '1219',\n",
       " '101',\n",
       " '874',\n",
       " '85',\n",
       " '1324',\n",
       " '311',\n",
       " '441',\n",
       " '998',\n",
       " '114',\n",
       " '58',\n",
       " '722',\n",
       " '1035',\n",
       " '275',\n",
       " '350',\n",
       " '391',\n",
       " '76',\n",
       " '806',\n",
       " '41',\n",
       " '406',\n",
       " '252',\n",
       " '1166',\n",
       " '1138',\n",
       " '1165',\n",
       " '880',\n",
       " '665',\n",
       " '812',\n",
       " '1157',\n",
       " '685',\n",
       " '638',\n",
       " '1101',\n",
       " '702',\n",
       " '1282',\n",
       " '129',\n",
       " '1212',\n",
       " '13',\n",
       " '1065',\n",
       " '352',\n",
       " '991',\n",
       " '70',\n",
       " '951',\n",
       " '654',\n",
       " '882',\n",
       " '687',\n",
       " '181',\n",
       " '732',\n",
       " '1008',\n",
       " '431',\n",
       " '302',\n",
       " '720',\n",
       " '266',\n",
       " '1244',\n",
       " '969',\n",
       " '410',\n",
       " '831',\n",
       " '1250',\n",
       " '551',\n",
       " '917',\n",
       " '297',\n",
       " '211',\n",
       " '921',\n",
       " '1161',\n",
       " '695',\n",
       " '1377',\n",
       " '319',\n",
       " '899',\n",
       " '446',\n",
       " '193',\n",
       " '554',\n",
       " '681',\n",
       " '1297',\n",
       " '968',\n",
       " '540',\n",
       " '156',\n",
       " '1305',\n",
       " '1375',\n",
       " '198',\n",
       " '730',\n",
       " '143',\n",
       " '262',\n",
       " '368',\n",
       " '83',\n",
       " '1190',\n",
       " '1362',\n",
       " '516',\n",
       " '422',\n",
       " '873',\n",
       " '445',\n",
       " '216',\n",
       " '561',\n",
       " '529',\n",
       " '373',\n",
       " '1195',\n",
       " '110',\n",
       " '226',\n",
       " '163',\n",
       " '60',\n",
       " '315',\n",
       " '595',\n",
       " '948',\n",
       " '77',\n",
       " '31',\n",
       " '826',\n",
       " '1218',\n",
       " '1270',\n",
       " '594',\n",
       " '1314',\n",
       " '1332',\n",
       " '1013',\n",
       " '169',\n",
       " '223',\n",
       " '1029',\n",
       " '1376',\n",
       " '1341',\n",
       " '1385',\n",
       " '456',\n",
       " '625',\n",
       " '976',\n",
       " '25',\n",
       " '648',\n",
       " '490',\n",
       " '1162',\n",
       " '425',\n",
       " '404',\n",
       " '201',\n",
       " '813',\n",
       " '855',\n",
       " '758',\n",
       " '1253',\n",
       " '389',\n",
       " '587',\n",
       " '1339',\n",
       " '933',\n",
       " '1389',\n",
       " '1003',\n",
       " '527',\n",
       " '1097',\n",
       " '844',\n",
       " '979',\n",
       " '1346',\n",
       " '1271',\n",
       " '796',\n",
       " '827',\n",
       " '1334',\n",
       " '701',\n",
       " '242',\n",
       " '1102',\n",
       " '401',\n",
       " '759',\n",
       " '1310',\n",
       " '568',\n",
       " '734',\n",
       " '93',\n",
       " '1140',\n",
       " '342',\n",
       " '675',\n",
       " '791',\n",
       " '728',\n",
       " '1356',\n",
       " '733',\n",
       " '526',\n",
       " '1363',\n",
       " '762',\n",
       " '536',\n",
       " '1239',\n",
       " '1233',\n",
       " '1268',\n",
       " '699',\n",
       " '553',\n",
       " '336',\n",
       " '359',\n",
       " '532',\n",
       " '1007',\n",
       " '939',\n",
       " '11',\n",
       " '670',\n",
       " '34',\n",
       " '166',\n",
       " '1108',\n",
       " '585',\n",
       " '865',\n",
       " '385',\n",
       " '674',\n",
       " '962',\n",
       " '1122',\n",
       " '1338',\n",
       " '777',\n",
       " '769',\n",
       " '980',\n",
       " '162',\n",
       " '1230',\n",
       " '281',\n",
       " '778',\n",
       " '1378',\n",
       " '349',\n",
       " '1392',\n",
       " '1143',\n",
       " '1347',\n",
       " '230',\n",
       " '774',\n",
       " '519',\n",
       " '87',\n",
       " '176',\n",
       " '237',\n",
       " '1098',\n",
       " '644',\n",
       " '916',\n",
       " '1315',\n",
       " '545',\n",
       " '458',\n",
       " '533',\n",
       " '776',\n",
       " '542',\n",
       " '1041',\n",
       " '1206',\n",
       " '81',\n",
       " '1031',\n",
       " '707',\n",
       " '864',\n",
       " '927',\n",
       " '828',\n",
       " '1000',\n",
       " '27',\n",
       " '520',\n",
       " '474',\n",
       " '1337',\n",
       " '369',\n",
       " '1068',\n",
       " '30',\n",
       " '879',\n",
       " '1343',\n",
       " '1137',\n",
       " '1084',\n",
       " '508',\n",
       " '95',\n",
       " '213',\n",
       " '924',\n",
       " '455',\n",
       " '296',\n",
       " '740',\n",
       " '322',\n",
       " '657',\n",
       " '517',\n",
       " '1120',\n",
       " '627',\n",
       " '1273',\n",
       " '938',\n",
       " '1269',\n",
       " '745',\n",
       " '795',\n",
       " '274',\n",
       " '1285',\n",
       " '1224',\n",
       " '16',\n",
       " '239',\n",
       " '318',\n",
       " '1115',\n",
       " '1173',\n",
       " '1226',\n",
       " '1187',\n",
       " '1360',\n",
       " '1280',\n",
       " '739',\n",
       " '601',\n",
       " '420',\n",
       " '934',\n",
       " '499',\n",
       " '572',\n",
       " '80',\n",
       " '854',\n",
       " '708',\n",
       " '189',\n",
       " '1056',\n",
       " '1201',\n",
       " '334',\n",
       " '19',\n",
       " '1117',\n",
       " '292',\n",
       " '44',\n",
       " '99',\n",
       " '505',\n",
       " '1243',\n",
       " '1014',\n",
       " '684',\n",
       " '1104',\n",
       " '97',\n",
       " '1293',\n",
       " '245',\n",
       " '743',\n",
       " '838',\n",
       " '549',\n",
       " '912',\n",
       " '464',\n",
       " '451',\n",
       " '580',\n",
       " '26',\n",
       " '1006',\n",
       " '1030',\n",
       " '1130',\n",
       " '1390',\n",
       " '206',\n",
       " '963',\n",
       " '160',\n",
       " '1209',\n",
       " '1326',\n",
       " '442',\n",
       " '1150',\n",
       " '1185',\n",
       " '683',\n",
       " '40',\n",
       " '1153',\n",
       " '615',\n",
       " '1066',\n",
       " '814',\n",
       " '504',\n",
       " '1183',\n",
       " '1327',\n",
       " '447',\n",
       " '290',\n",
       " '1071',\n",
       " '717',\n",
       " '116',\n",
       " '632',\n",
       " '577',\n",
       " '703',\n",
       " '706',\n",
       " '222',\n",
       " '1052',\n",
       " '366',\n",
       " '592',\n",
       " '439',\n",
       " '1005',\n",
       " '98',\n",
       " '398',\n",
       " '1291',\n",
       " '1311',\n",
       " '155',\n",
       " '73',\n",
       " '449',\n",
       " '1371',\n",
       " '1094',\n",
       " '346',\n",
       " '215',\n",
       " '45',\n",
       " '472',\n",
       " '892',\n",
       " '894',\n",
       " '1370',\n",
       " '344',\n",
       " '676',\n",
       " '1281',\n",
       " '433',\n",
       " '1393',\n",
       " '631',\n",
       " '1160',\n",
       " '1083',\n",
       " '159',\n",
       " '1398',\n",
       " '438',\n",
       " '1064',\n",
       " '480',\n",
       " '736',\n",
       " '1072',\n",
       " '590',\n",
       " '1093',\n",
       " '1247',\n",
       " '240',\n",
       " '803',\n",
       " '1004',\n",
       " '1383',\n",
       " '362',\n",
       " '571',\n",
       " '902',\n",
       " '1260',\n",
       " '6',\n",
       " '710',\n",
       " '801',\n",
       " '323',\n",
       " '1036',\n",
       " '171',\n",
       " '107',\n",
       " '130',\n",
       " '957',\n",
       " '1248',\n",
       " '1106',\n",
       " '1009',\n",
       " '424',\n",
       " '940',\n",
       " '4',\n",
       " '941',\n",
       " '96',\n",
       " '409',\n",
       " '197',\n",
       " '440',\n",
       " '1277',\n",
       " '818',\n",
       " '809',\n",
       " '1077',\n",
       " '1198',\n",
       " '667',\n",
       " '889',\n",
       " '149',\n",
       " '858',\n",
       " '103',\n",
       " '444',\n",
       " '37',\n",
       " '304',\n",
       " '380',\n",
       " '66',\n",
       " '1235',\n",
       " '1010',\n",
       " '9',\n",
       " '651',\n",
       " '584',\n",
       " '537',\n",
       " '353',\n",
       " '1062',\n",
       " '937',\n",
       " '465',\n",
       " '1080',\n",
       " '246',\n",
       " '1047',\n",
       " '983',\n",
       " '15',\n",
       " '727',\n",
       " '556',\n",
       " '797',\n",
       " '671',\n",
       " '72',\n",
       " '1188',\n",
       " '918',\n",
       " '511',\n",
       " '755',\n",
       " '1024',\n",
       " '785',\n",
       " '738',\n",
       " '236',\n",
       " '1119',\n",
       " '217',\n",
       " '1032',\n",
       " '1374',\n",
       " '448',\n",
       " '484',\n",
       " '863',\n",
       " '856',\n",
       " '513',\n",
       " '379',\n",
       " '570',\n",
       " '1055',\n",
       " '347',\n",
       " '1081',\n",
       " '351',\n",
       " '1020',\n",
       " '630',\n",
       " '766',\n",
       " '360',\n",
       " '139',\n",
       " '563',\n",
       " '993',\n",
       " '462',\n",
       " '145',\n",
       " '887',\n",
       " '413',\n",
       " '183',\n",
       " '583',\n",
       " '573',\n",
       " '603',\n",
       " '1',\n",
       " '859',\n",
       " '1210',\n",
       " '800',\n",
       " '468',\n",
       " '1211',\n",
       " '255',\n",
       " '634',\n",
       " '287',\n",
       " '901',\n",
       " '152',\n",
       " '28',\n",
       " '1154',\n",
       " '1345',\n",
       " '930',\n",
       " '787',\n",
       " '1134',\n",
       " '764',\n",
       " '679',\n",
       " '1129',\n",
       " '719',\n",
       " '132',\n",
       " '929',\n",
       " '115',\n",
       " '1151',\n",
       " '248',\n",
       " '1074',\n",
       " '816',\n",
       " '928',\n",
       " '1313',\n",
       " '173',\n",
       " '843',\n",
       " '961',\n",
       " '235',\n",
       " '1181',\n",
       " '655',\n",
       " '1344',\n",
       " '919',\n",
       " '388',\n",
       " '666',\n",
       " '1301',\n",
       " '923',\n",
       " '35',\n",
       " '786',\n",
       " '1213',\n",
       " '370',\n",
       " '144',\n",
       " '518',\n",
       " '1330',\n",
       " '936',\n",
       " '600',\n",
       " '164',\n",
       " '1053',\n",
       " '79',\n",
       " '414',\n",
       " '1381',\n",
       " '32',\n",
       " '421',\n",
       " '185',\n",
       " '990',\n",
       " '229',\n",
       " '1322',\n",
       " '186',\n",
       " '904',\n",
       " '283',\n",
       " '1114',\n",
       " '1296',\n",
       " '170',\n",
       " '686',\n",
       " '125',\n",
       " '1349',\n",
       " '122',\n",
       " '365',\n",
       " '709',\n",
       " '649',\n",
       " '1179',\n",
       " '177',\n",
       " '157',\n",
       " '1229',\n",
       " '815',\n",
       " '146',\n",
       " '773',\n",
       " '1391',\n",
       " '767',\n",
       " '1333',\n",
       " '1203',\n",
       " '1240',\n",
       " '790',\n",
       " '305',\n",
       " '677',\n",
       " '49',\n",
       " '1289',\n",
       " '124',\n",
       " '656',\n",
       " '564',\n",
       " '53',\n",
       " '566',\n",
       " '660',\n",
       " '7',\n",
       " '432',\n",
       " '1225',\n",
       " '375',\n",
       " '782',\n",
       " '205',\n",
       " '575',\n",
       " '212',\n",
       " '363',\n",
       " '1040',\n",
       " '569',\n",
       " '599',\n",
       " '1373',\n",
       " '1274',\n",
       " '757',\n",
       " '1319',\n",
       " '1325',\n",
       " '174',\n",
       " '179',\n",
       " '1061',\n",
       " '522',\n",
       " '673',\n",
       " '300',\n",
       " '704',\n",
       " '417',\n",
       " '662',\n",
       " '225']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the structural and aeroelastic problems associated with flight of high speed aircraft .\"\n",
    "try:\n",
    "    pkl_file = open(os.path.join('.\\input', 'data', 'train.pickle'), 'rb')\n",
    "    arr_file = pickle.load(pkl_file)\n",
    "    tfidfVectorizer = pickle.load(pkl_file)\n",
    "    tfidf_scores = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "except:\n",
    "    data, arr_file = read_data()\n",
    "    tfidfVectorizer, tfidf_scores = build_tf_idf_sklearn(data)\n",
    "    with open(os.path.join('.\\input', 'data', 'train.pickle'), mode='wb') as f:\n",
    "        pickle.dump(arr_file, f)\n",
    "        pickle.dump(tfidfVectorizer, f)\n",
    "        pickle.dump(tfidf_scores, f)\n",
    "    f.close()\n",
    "        \n",
    "feature_names = tfidfVectorizer.get_feature_names()\n",
    "ans = get_relevant_ranking_for_query(\n",
    "    query, tfidfVectorizer, tfidf_scores, feature_names, arr_file\n",
    ")\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3 tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
